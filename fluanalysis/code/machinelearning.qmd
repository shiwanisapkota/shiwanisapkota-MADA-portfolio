---
title: "Machine Learning"
format: html
editor: visual
---

**LOADING REQUIRED PACKAGES**

```{r, warning = FALSE}
library(here)
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(ranger)
library(rpart)
library(glmnet)
library(vip)
library(rpart.plot)
library(performance)
library(yardstick)
library(recipes)
```

**LOADING DATA**

```{r}
fludata_clean11 <- readRDS(here("fluanalysis", "data", "fludata_clean_module11.rds"))
glimpse(fludata_clean11)
```

**DATA SETUP**

```{r}
# Setting the random seed to 123
set.seed(123)

# Splitting dataset into 70% training and 30% testing and using BodyTemp outcome as stratification
data_split <- initial_split(fludata_clean11, prop = 7/10, strata = BodyTemp)
  
# Creating data frames for the two sets:
train_data <- training(data_split)
test_data  <- testing(data_split)

# Creating 5-fold cross-validation, 5 times repeated
CV_fold_data <- vfold_cv(train_data, v = 5, repeats = 5, strata = BodyTemp)

# Creating a recipe
recipe_data <- recipe(BodyTemp ~ ., data = train_data) %>%
  step_dummy(all_nominal(), -all_outcomes())
```

**NULL MODEL PERFORMANCE**

```{r}
# Using train data
# Creating a recipe for null model
recipe_null_train <- recipe(BodyTemp ~ 1, data = train_data) %>%
  step_dummy(all_nominal(), -all_outcomes())

# Creating a linear model recipe
recipe_null_logistic <- linear_reg() %>% 
  set_engine("lm") %>% 
  set_mode("regression")

# Creating workflow pairing model and recipe 
workflow_null_train <- workflow() %>% 
  add_model(recipe_null_logistic) %>% 
  add_recipe(recipe_null_train)

# Fitting null model with the folds created from train data 
train_null <- fit_resamples(workflow_null_train, resamples = CV_fold_data)

# Computing RMSE for train data
metrics_null_train <- collect_metrics(train_null)
metrics_null_train
```

From the null model, we got RMSE as 1.21.

**MODEL TUNING AND FITTING: TREE MODEL**

```{r}
# Tuning hyperparameters by creating model specification that identifies which hyperparameters we are planning to tune
tune_tree_model <- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune()) %>%
  set_engine("rpart") %>% 
  set_mode("regression")
tune_tree_model

# Creating a regular grid of values for using some convenience functions for each hyperparameter
tree_grid <- grid_regular(cost_complexity(), tree_depth(), levels = 5)

tree_grid %>% count(tree_depth)

# Tuning the workflow using model specification and recipe and model
tree_wf <- workflow() %>%
  add_model(tune_tree_model) %>%
  add_recipe(recipe_data)

# Tuning using cross-validation and the tune_grid() function
tree_res <- tree_wf %>% 
  tune_grid(resamples = CV_fold_data,
    grid = tree_grid)
```

**MODEL EVALUATION: TREE MODEL**

```{r}
# Plotting the above results
tree_res %>% autoplot()

# Getting the best-fit model
tree_res %>%
  show_best()

best_tree <- tree_res %>%
  select_best(metric = "rmse")

# Getting the final workflow
final_wf <- tree_wf %>% 
  finalize_workflow(best_tree)

# Fitting to the training data with the final workflow
final_fit <- final_wf %>%
  fit(train_data)

# Plotting the final fit
rpart.plot(extract_fit_parsnip(final_fit)$fit, roundint = FALSE)

# Predicted outcomes
predicted_fit <- predict(final_fit, train_data)
```

From the tree model, we got RMSE as 1.19.

**MODEL TUNING AND FITTING: LASSO MODEL**

```{r}
# Building the model
model_lasso <- linear_reg(penalty = tune(), mixture = 1) %>% set_engine("glmnet")

# We will be using the recipe (recipe_data) that we created above 
# Creating the workflow
wf_lasso <- workflow() %>% 
  add_model(model_lasso) %>% 
  add_recipe(recipe_data)

# Model tuning using grid
lasso_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))
lasso_grid %>% top_n(-5)
lasso_grid %>% top_n(5)

# Tuning the model using tune_grid() function
res_lasso <- wf_lasso %>% tune_grid(resamples = CV_fold_data, grid = lasso_grid,
    control = control_grid(verbose = FALSE, save_pred = TRUE), metrics = NULL)

res_lasso %>% collect_metrics()
```

**MODEL EVALUATION: LASSO MODEL**

```{r}
# Plotting the above results
res_lasso %>% autoplot()

# Getting the best-fit model
res_lasso %>%
  show_best()

best_lasso <- res_lasso %>%
  select_best(metric = "rmse")

# Getting the final workflow
final_lasso_wf <- wf_lasso %>% 
  finalize_workflow(best_lasso)

# Fitting to the training data with the final workflow
final_lasso_fit <- final_lasso_wf %>% fit(train_data) 

# Plotting the final fit
plot_lasso <- extract_fit_engine(final_lasso_fit)
plot(plot_lasso, "lambda")

# Predicted outcomes
predicted_lasso_fit <- predict(final_lasso_fit, train_data)
```

From the Lasso model, we got RMSE as 1.16.

**MODEL TUNING AND FITTING: RANDOM FOREST MODEL**

```{r}
# Detecting the cores
cores <- parallel::detectCores()
cores

# Building the model
model_randomforest <- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_engine("ranger",importance = "impurity", num.threads = cores) %>%
  set_mode("regression")

# We will be using the recipe (recipe_data) that we created above 
# Creating the workflow
wf_randomforest <- workflow() %>%
  add_model(model_randomforest) %>%
  add_recipe(recipe_data)

# Model tuning
extract_parameter_set_dials(model_randomforest)

# Tuning the model using tune_grid() function
res_randomforest <- wf_randomforest %>% tune_grid(resamples = CV_fold_data, grid = 25,
    control = control_grid(save_pred = TRUE), metrics = NULL)
```

**MODEL EVALUATION: RANDOM FOREST MODEL**

```{r}
# Plotting the above results
res_randomforest %>% autoplot()

# Getting the best-fit model
res_randomforest %>%
  show_best()

best_randomforest <- res_randomforest %>%
  select_best(metric = "rmse")

# Getting the final workflow
final_randomforest_wf <- wf_randomforest %>% 
  finalize_workflow(best_randomforest)

# Fitting to the training data with the final workflow
final_randomforest_fit <- final_randomforest_wf %>% fit(train_data) 
final_randomforest_fit %>% extract_fit_parsnip() %>% vip(num_features = 28)

# Plotting the final fit
plot_randomforest <- extract_fit_engine(final_randomforest_fit)
vip(plot_randomforest)

# Predicted outcomes
predicted_randomforest_fit <- predict(final_randomforest_fit, train_data)
```

From the random forest model, we got RMSE as 1.17.

Based on the above results, lasso model performed the best as it had the lowest RMSE compared to others. Hence, lasso model was selected.

**FINAL EVALUATION**

```{r}
# Fitting the final lasso model on split data
final_lasso_test <- final_lasso_wf %>% last_fit(data_split) 

final_lasso_test %>% collect_metrics()
```

From the above final model, we got RMSE as 1.16.
